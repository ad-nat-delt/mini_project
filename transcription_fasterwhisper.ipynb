{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from faster_whisper import WhisperModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: OMP_NUM_THREADS=4\n"
     ]
    }
   ],
   "source": [
    "%env OMP_NUM_THREADS=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Estimating duration from bitrate, this may be inaccurate\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected language 'en' with probability 0.999874\n",
      "[0.00s -> 6.14s]  Smoke from hundreds of wildfires in Canada is triggering air quality alerts throughout the U.S.\n",
      "[6.54s -> 10.82s]  Skylines from Maine to Maryland to Minnesota are gray and smoggy.\n",
      "[11.24s -> 15.56s]  And in some places, the air quality warnings include the warning to stay inside.\n",
      "[16.04s -> 19.72s]  We wanted to better understand what's happening here and why, so we called Peter DiCarlo,\n",
      "[20.14s -> 25.26s]  an associate professor in the Department of Environmental Health and Engineering at Johns Hopkins University.\n",
      "[25.66s -> 26.32s]  Good morning, Professor.\n",
      "[27.56s -> 28.56s]  Good morning.\n",
      "[28.56s -> 37.12s]  So what is it about the conditions right now that have caused this round of wildfires to affect so many people so far away?\n",
      "[38.88s -> 40.26s]  Well, there's a couple of things.\n",
      "[40.56s -> 45.66s]  The season has been pretty dry already, and then the fact that we're getting hit in the U.S.\n",
      "[45.96s -> 50.56s]  is because there's a couple weather systems that are essentially channeling the smoke from those Canadian wildfires\n",
      "[50.56s -> 55.74s]  through Pennsylvania into the mid-Atlantic and the Northeast and kind of just dropping the smoke there.\n",
      "[56.08s -> 58.52s]  So what is it in this haze that makes it?\n",
      "[58.68s -> 60.54s]  It's harmful, and I'm assuming it is harmful.\n",
      "[62.42s -> 62.92s]  It is.\n",
      "[63.00s -> 63.26s]  It is.\n",
      "[63.36s -> 66.44s]  The levels outside right now in Baltimore are considered unhealthy,\n",
      "[66.96s -> 71.58s]  and most of that is due to what's called particulate matter, which are tiny particles,\n",
      "[72.24s -> 74.52s]  microscopic, smaller than the width of your hair,\n",
      "[75.02s -> 79.82s]  that can get into your lungs and impact your respiratory system, your cardiovascular system,\n",
      "[80.26s -> 82.40s]  and even your neurological, your brain.\n",
      "[83.14s -> 85.44s]  What makes this particularly harmful?\n",
      "[85.60s -> 87.40s]  Is it the volume of particulate?\n",
      "[88.06s -> 88.40s]  Is it something?\n",
      "[88.56s -> 90.30s]  You know, what is it exactly?\n",
      "[90.38s -> 92.02s]  Can you just drill down on that a little bit more?\n",
      "[93.40s -> 98.16s]  Yeah, so the concentration of particulate matter, I was looking at some of the monitors that we have,\n",
      "[98.26s -> 103.50s]  was reaching levels of what are, in science speak, 150 micrograms per meter cubed,\n",
      "[103.58s -> 107.06s]  which is more than 10 times what the annual average should be\n",
      "[107.06s -> 113.00s]  and about four times higher than what you're supposed to have on a 24-hour average.\n",
      "[113.12s -> 118.38s]  And so the concentrations of these particles in the air are just much, much, much higher\n"
     ]
    }
   ],
   "source": [
    "model_size = \"large-v3\"\n",
    "\n",
    "# Run on GPU with FP16\n",
    "# model = WhisperModel(model_size, device=\"cuda\", compute_type=\"float16\")\n",
    "\n",
    "# or run on GPU with INT8\n",
    "# model = WhisperModel(model_size, device=\"cuda\", compute_type=\"int8_float16\")\n",
    "# or run on CPU with INT8\n",
    "model = WhisperModel(model_size, device=\"cpu\", compute_type=\"int8\")\n",
    "\n",
    "segments, info = model.transcribe(\"20230607_me_canadian_wildfires(1).mp3\", beam_size=5)\n",
    "\n",
    "print(\"Detected language '%s' with probability %f\" % (info.language, info.language_probability))\n",
    "\n",
    "for segment in segments:\n",
    "    print(\"[%.2fs -> %.2fs] %s\" % (segment.start, segment.end, segment.text))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
